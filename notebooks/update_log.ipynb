{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Lifting Tracker\n",
    "Sync workout JSON files, compute metrics, and visualize progress toward fitness goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# === PLOT STYLING ===\n",
    "plt.rcParams.update({\n",
    "    # Font sizes\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"figure.titlesize\": 18,\n",
    "    # Bold fonts\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    # Thicker spines\n",
    "    \"axes.linewidth\": 2,\n",
    "    \"xtick.major.width\": 1.5,\n",
    "    \"ytick.major.width\": 1.5,\n",
    "    \"xtick.major.size\": 6,\n",
    "    \"ytick.major.size\": 6,\n",
    "    # Grid\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.3,\n",
    "})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "EXCEL_FILE = \"workout_log.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movement Family Mapping\n",
    "FAMILY_MAP = {\n",
    "    # Squat\n",
    "    \"Front Squat\": \"Squat\", \"Back Squat\": \"Squat\", \"Zercher Squat\": \"Squat\",\n",
    "    # Hinge\n",
    "    \"Deadlift\": \"Hinge\", \"Zercher Deadlift\": \"Hinge\", \"Romanian Deadlift\": \"Hinge\",\n",
    "    \"RDL\": \"Hinge\", \"Kettlebell Swings\": \"Hinge\",\n",
    "    # Horizontal Push\n",
    "    \"Barbell Bench Press\": \"Push (H)\", \"Incline BB Press\": \"Push (H)\", \"DB Press\": \"Push (H)\",\n",
    "    \"Incline DB Press\": \"Push (H)\", \"Incline DB Fly\": \"Push (H)\", \"Dips\": \"Push (H)\",\n",
    "    \"Dumbbell Pullover\": \"Push (H)\",\n",
    "    # Vertical Push\n",
    "    \"Standing OHP\": \"Push (V)\", \"Overhead Press\": \"Push (V)\", \"DB Shoulder Press\": \"Push (V)\",\n",
    "    \"Standing Overhead Press\": \"Push (V)\",\n",
    "    # Horizontal Pull\n",
    "    \"Bent over Barbell Rows\": \"Pull (H)\", \"Bent over barbell row\": \"Pull (H)\", \"Cable Rows\": \"Pull (H)\",\n",
    "    # Vertical Pull\n",
    "    \"Pull Ups\": \"Pull (V)\", \"Lat Pulldown\": \"Pull (V)\",\n",
    "    # Isolation\n",
    "    \"Incline Bicep Curl\": \"Isolation\", \"Barbell Bicep Curl\": \"Isolation\",\n",
    "    \"Cable Bicep Curl\": \"Isolation\", \"Cable Tricep Pushdown\": \"Isolation\",\n",
    "    # Core\n",
    "    \"Cable Crunches\": \"Core\"\n",
    "}\n",
    "\n",
    "# 2026 Strength Milestones: (weight_kg, reps)\n",
    "# Keys are search terms (case-insensitive partial match against Movement)\n",
    "MILESTONES = {\n",
    "    \"Squat\": [(100, 20), (140, 5)],\n",
    "    \"Deadlift\": [(200, 1), (140, 8)],\n",
    "    \"Overhead Press\": [(60, 3), (40, 12)],\n",
    "    \"Bench Press\": [(100, 2), (60, 10)],\n",
    "    \"barbell row\": [(80, 6), (60, 12)],\n",
    "    \"Kettlebell\": [(24, 80)]\n",
    "}\n",
    "\n",
    "MOVEMENT_PATTERNS = [\"Squat\", \"Hinge\", \"Push (H)\", \"Push (V)\", \"Pull (H)\", \"Pull (V)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sync",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_json_to_excel(data_dir=DATA_DIR, excel_filename=EXCEL_FILE):\n",
    "    \"\"\"Sync workout JSON files to Excel log, deduplicating by timestamp.\"\"\"\n",
    "    excel_path = os.path.join(data_dir, excel_filename)\n",
    "    \n",
    "    # Load existing data\n",
    "    existing_timestamps = set()\n",
    "    if os.path.exists(excel_path):\n",
    "        df_existing = pd.read_excel(excel_path)\n",
    "        if not df_existing.empty:\n",
    "            existing_timestamps = set(df_existing[\"Timestamp\"].astype(str).str.strip().unique())\n",
    "            print(f\"Loaded {len(existing_timestamps)} existing sessions from Excel.\")\n",
    "    else:\n",
    "        print(\"Excel log not found. Starting fresh.\")\n",
    "        df_existing = pd.DataFrame()\n",
    "\n",
    "    # Find and process JSON files\n",
    "    new_records = []\n",
    "    json_files = glob.glob(os.path.join(data_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files in {data_dir}.\")\n",
    "\n",
    "    for file in json_files:\n",
    "        # Extract timestamp from filename (YYYYMMDD_HHMMSS.json)\n",
    "        basename = os.path.splitext(os.path.basename(file))[0]\n",
    "        try:\n",
    "            file_ts = datetime.strptime(basename, \"%Y%m%d_%H%M%S\")\n",
    "            file_ts_str = file_ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            file_ts_str = None\n",
    "        \n",
    "        with open(file, \"r\") as f:\n",
    "            try:\n",
    "                session_data = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Could not decode {file}. Skipping.\")\n",
    "                continue\n",
    "        \n",
    "        if not session_data:\n",
    "            continue\n",
    "            \n",
    "        # Use file timestamp if record timestamp is missing/None\n",
    "        session_ts = str(session_data[0].get(\"Timestamp\") or file_ts_str).strip()\n",
    "        \n",
    "        if session_ts not in existing_timestamps and session_ts != \"None\":\n",
    "            # Apply file timestamp to records missing timestamps\n",
    "            for record in session_data:\n",
    "                if not record.get(\"Timestamp\") and file_ts_str:\n",
    "                    record[\"Timestamp\"] = file_ts_str\n",
    "            new_records.extend(session_data)\n",
    "            existing_timestamps.add(session_ts)\n",
    "            print(f\"Adding session: {session_ts}\")\n",
    "        else:\n",
    "            print(f\"Skipping: {session_ts}\")\n",
    "\n",
    "    # Append and save\n",
    "    if new_records:\n",
    "        df_new = pd.DataFrame(new_records)\n",
    "        if \"Load_kg\" in df_new.columns and \"Reps\" in df_new.columns:\n",
    "            df_new[\"e1RM\"] = df_new[\"Load_kg\"] * (1 + df_new[\"Reps\"] / 30)\n",
    "        \n",
    "        df_final = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "        cols = [\"Timestamp\"] + [c for c in df_final.columns if c != \"Timestamp\"]\n",
    "        df_final = df_final[cols]\n",
    "        df_final.to_excel(excel_path, index=False)\n",
    "        print(f\"SUCCESS: {len(new_records)} sets written.\")\n",
    "    else:\n",
    "        print(\"No new data to sync.\")\n",
    "\n",
    "sync_json_to_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(data_dir=DATA_DIR, excel_filename=EXCEL_FILE):\n",
    "    \"\"\"Load Excel data and apply derived columns.\"\"\"\n",
    "    excel_path = os.path.join(data_dir, excel_filename)\n",
    "    df = pd.read_excel(excel_path)\n",
    "    \n",
    "    # Ensure Timestamp is datetime\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "    df[\"Date\"] = df[\"Timestamp\"].dt.date\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    df[\"Family\"] = df[\"Movement\"].map(FAMILY_MAP).fillna(\"Other\")\n",
    "    df[\"e1RM\"] = df[\"Load_kg\"] * (1 + df[\"Reps\"] / 30)\n",
    "    \n",
    "    if \"Volume_Load\" not in df.columns:\n",
    "        df[\"Volume_Load\"] = df[\"Load_kg\"] * df[\"Reps\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_and_prepare_data()\n",
    "latest_date = df[\"Date\"].max()\n",
    "latest_session = df[df[\"Date\"] == latest_date]\n",
    "\n",
    "print(f\"Loaded {len(df)} sets across {df['Date'].nunique()} sessions.\")\n",
    "print(f\"Latest session: {latest_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_tonnage",
   "metadata": {},
   "source": [
    "## Session Tonnage Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_tonnage",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_stats = df.groupby(\"Date\").agg({\n",
    "    \"Volume_Load\": \"sum\",\n",
    "    \"Intensity_RPE\": \"mean\",\n",
    "    \"Movement\": \"count\"\n",
    "}).rename(columns={\"Movement\": \"Set_Count\"}).reset_index()\n",
    "\n",
    "session_stats[\"MA_3\"] = session_stats[\"Volume_Load\"].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Volume over time\n",
    "ax1.bar(session_stats[\"Date\"], session_stats[\"Volume_Load\"], alpha=0.4, color=\"teal\", label=\"Session Tonnage\")\n",
    "ax1.plot(session_stats[\"Date\"], session_stats[\"MA_3\"], color=\"purple\", linewidth=2, marker=\"o\", label=\"3-Session MA\")\n",
    "avg_tonnage = session_stats[\"Volume_Load\"].mean()\n",
    "ax1.axhline(y=avg_tonnage, color=\"red\", linestyle=\"--\", alpha=0.5, label=f\"Avg: {avg_tonnage:.0f}kg\")\n",
    "ax1.set_ylabel(\"Volume Load (kg)\")\n",
    "ax1.set_title(\"Session Tonnage Over Time\")\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# RPE over time\n",
    "ax2.plot(session_stats[\"Date\"], session_stats[\"Intensity_RPE\"], marker=\"s\", color=\"orange\", linewidth=2)\n",
    "ax2.axhline(y=7, color=\"red\", linestyle=\"--\", alpha=0.4, label=\"RPE 7 Threshold\")\n",
    "ax2.set_ylabel(\"Average RPE\")\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.set_ylim(0, 10)\n",
    "ax2.set_title(\"Average Session Intensity\")\n",
    "ax2.legend()\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_latest",
   "metadata": {},
   "source": [
    "## Latest Session Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_latest_session",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. Volume distribution - Latest Session\n",
    "family_dist = latest_session.groupby(\"Family\")[\"Volume_Load\"].sum()\n",
    "axes[0].pie(family_dist, labels=family_dist.index, autopct=\"%1.1f%%\", startangle=140,\n",
    "            colors=sns.color_palette(\"viridis\", len(family_dist)), \n",
    "            textprops={\"fontsize\": 11, \"fontweight\": \"bold\"})\n",
    "axes[0].set_title(f\"Latest Session: {latest_date}\")\n",
    "\n",
    "# 2. Volume distribution - All Time\n",
    "total_dist = df.groupby(\"Family\")[\"Volume_Load\"].sum()\n",
    "axes[1].pie(total_dist, labels=total_dist.index, autopct=\"%1.1f%%\", startangle=140,\n",
    "            colors=sns.color_palette(\"viridis\", len(total_dist)),\n",
    "            textprops={\"fontsize\": 11, \"fontweight\": \"bold\"})\n",
    "axes[1].set_title(\"All-Time Volume Distribution\")\n",
    "\n",
    "# 3. Top sets: Load vs RPE (latest session)\n",
    "top_sets = latest_session.sort_values(\"Load_kg\", ascending=False).drop_duplicates(\"Movement\")\n",
    "sns.scatterplot(data=top_sets, x=\"Load_kg\", y=\"Intensity_RPE\", hue=\"Movement\", s=200, ax=axes[2])\n",
    "axes[2].set_title(\"Latest Session: Top Sets\")\n",
    "axes[2].set_xlabel(\"Load (kg)\")\n",
    "axes[2].set_ylabel(\"RPE\")\n",
    "axes[2].set_xlim(left=0)\n",
    "axes[2].set_ylim(0, 10.5)\n",
    "axes[2].legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "\n",
    "plt.suptitle(\"Volume Distribution & Session Quality\", fontsize=16, fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_strength",
   "metadata": {},
   "source": [
    "## Strength Matrix (Current e1RM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_strength_matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best e1RM for each movement\n",
    "max_perf = df.sort_values(\"e1RM\", ascending=False).drop_duplicates(\"Movement\")\n",
    "matrix_data = max_perf[[\"Movement\", \"Family\", \"e1RM\", \"Load_kg\", \"Reps\"]].sort_values(\"Family\")\n",
    "\n",
    "plt.figure(figsize=(12, len(matrix_data) * 0.5))\n",
    "sns.barplot(data=matrix_data, x=\"e1RM\", y=\"Movement\", hue=\"Family\", dodge=False, palette=\"flare\")\n",
    "\n",
    "for i, row in enumerate(matrix_data.itertuples()):\n",
    "    plt.text(row.e1RM + 1, i, f\"{row.Load_kg}kg x {row.Reps}\", va=\"center\", fontsize=9)\n",
    "\n",
    "plt.title(\"Current Predicted 1RM by Movement\")\n",
    "plt.xlabel(\"Estimated 1RM (kg)\")\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.grid(axis=\"x\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mwoznyftuv7",
   "metadata": {},
   "source": [
    "## e1RM Progression Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8j57sv0asw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track e1RM progression for key compound movements\n",
    "key_movements = [\"Deadlift\", \"Overhead Press\", \"Bench Press\", \"Squat\", \"Row\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "for move in key_movements:\n",
    "    move_df = df[df[\"Movement\"].str.contains(move, case=False, na=False)].copy()\n",
    "    if not move_df.empty:\n",
    "        # Get best e1RM per session\n",
    "        best_per_session = move_df.groupby(\"Date\")[\"e1RM\"].max().reset_index()\n",
    "        ax.plot(best_per_session[\"Date\"], best_per_session[\"e1RM\"], \n",
    "                marker=\"o\", linewidth=2.5, markersize=8, label=move)\n",
    "\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Estimated 1RM (kg)\")\n",
    "ax.set_title(\"Strength Progression: e1RM Over Time\")\n",
    "ax.legend(loc=\"upper left\", framealpha=0.9)\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_balance",
   "metadata": {},
   "source": [
    "## Movement Pattern Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_pattern_balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_radar(stats, title, ax):\n",
    "    \"\"\"Plot radar chart for movement pattern balance.\"\"\"\n",
    "    values = stats.reindex(MOVEMENT_PATTERNS, fill_value=0).values.flatten().tolist()\n",
    "    values += values[:1]  # Close polygon\n",
    "    angles = [n / len(MOVEMENT_PATTERNS) * 2 * np.pi for n in range(len(MOVEMENT_PATTERNS))]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax.plot(angles, values, color=\"#8a2be2\", linewidth=2)\n",
    "    ax.fill(angles, values, color=\"#da70d6\", alpha=0.3)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(MOVEMENT_PATTERNS)\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Latest session balance\n",
    "session_vol = latest_session.groupby(\"Family\")[\"Volume_Load\"].sum()\n",
    "plot_radar(session_vol, f\"Latest Session: {latest_date}\", ax1)\n",
    "\n",
    "# All-time balance\n",
    "total_vol = df.groupby(\"Family\")[\"Volume_Load\"].sum()\n",
    "plot_radar(total_vol, \"All-Time Pattern Balance\", ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_composition",
   "metadata": {},
   "source": [
    "## Volume Composition Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_volume_composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked area chart by family\n",
    "pivot_df = df.pivot_table(index=\"Date\", columns=\"Family\", values=\"Volume_Load\", aggfunc=\"sum\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "pivot_df.plot(kind=\"area\", stacked=True, ax=plt.gca(), colormap=\"viridis\", alpha=0.7)\n",
    "\n",
    "plt.title(\"Volume Composition Over Time\")\n",
    "plt.ylabel(\"Volume Load (kg)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.legend(title=\"Movement Family\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.grid(axis=\"y\", linestyle=\":\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kno25xnznu",
   "metadata": {},
   "source": [
    "## Set Quality & Training Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8xvq7bh9qxo",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# 1. Set Quality Scatter: Volume vs RPE by Family\n",
    "scatter = sns.scatterplot(data=df, x=\"Volume_Load\", y=\"Intensity_RPE\", \n",
    "                          hue=\"Family\", size=\"Load_kg\", sizes=(50, 400), \n",
    "                          alpha=0.6, ax=ax1, palette=\"viridis\")\n",
    "ax1.axhline(y=7, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.5, label=\"RPE 7 (Effective Reps)\")\n",
    "ax1.set_xlabel(\"Volume Load (kg)\")\n",
    "ax1.set_ylabel(\"RPE\")\n",
    "ax1.set_title(\"Set Quality: Volume vs Intensity\")\n",
    "ax1.set_ylim(0, 10.5)\n",
    "ax1.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "\n",
    "# 2. RPE Distribution Histogram\n",
    "ax2.hist(df[\"Intensity_RPE\"].dropna(), bins=np.arange(0, 11, 0.5), \n",
    "         color=\"#8a2be2\", edgecolor=\"black\", linewidth=1.2, alpha=0.7)\n",
    "ax2.axvline(x=df[\"Intensity_RPE\"].mean(), color=\"red\", linestyle=\"--\", \n",
    "            linewidth=2.5, label=f\"Mean: {df['Intensity_RPE'].mean():.1f}\")\n",
    "ax2.axvline(x=7, color=\"orange\", linestyle=\"--\", linewidth=2, alpha=0.7, label=\"RPE 7 Threshold\")\n",
    "ax2.set_xlabel(\"RPE\")\n",
    "ax2.set_ylabel(\"Number of Sets\")\n",
    "ax2.set_title(\"Training Intensity Distribution\")\n",
    "ax2.set_xlim(0, 10.5)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "high_effort = (df[\"Intensity_RPE\"] >= 7).sum()\n",
    "total_sets = len(df)\n",
    "print(f\"\\nEffective sets (RPE >= 7): {high_effort}/{total_sets} ({high_effort/total_sets*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4kimga5gvay",
   "metadata": {},
   "source": [
    "## Training Style Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cu4zltpsbjb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Rep Range Distribution - Training Style\n",
    "rep_bins = [0, 5, 8, 12, 15, 100]\n",
    "rep_labels = [\"Strength\\n(1-5)\", \"Power\\n(6-8)\", \"Hypertrophy\\n(9-12)\", \"Endurance\\n(13-15)\", \"Conditioning\\n(15+)\"]\n",
    "df[\"Rep_Zone\"] = pd.cut(df[\"Reps\"], bins=rep_bins, labels=rep_labels, right=True)\n",
    "\n",
    "zone_counts = df[\"Rep_Zone\"].value_counts().reindex(rep_labels)\n",
    "colors = [\"#d62728\", \"#ff7f0e\", \"#2ca02c\", \"#1f77b4\", \"#9467bd\"]\n",
    "bars = ax1.bar(zone_counts.index, zone_counts.values, color=colors, edgecolor=\"black\", linewidth=1.5)\n",
    "ax1.set_ylabel(\"Number of Sets\")\n",
    "ax1.set_title(\"Training Style: Rep Range Distribution\")\n",
    "\n",
    "# Add percentage labels\n",
    "total = zone_counts.sum()\n",
    "for bar, count in zip(bars, zone_counts.values):\n",
    "    if count > 0:\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                f\"{count/total*100:.0f}%\", ha=\"center\", fontweight=\"bold\", fontsize=11)\n",
    "\n",
    "# 2. Volume per Set (Session Efficiency)\n",
    "session_efficiency = df.groupby(\"Date\").agg({\n",
    "    \"Volume_Load\": [\"sum\", \"count\"]\n",
    "}).droplevel(0, axis=1)\n",
    "session_efficiency.columns = [\"Total_Volume\", \"Set_Count\"]\n",
    "session_efficiency[\"Vol_Per_Set\"] = session_efficiency[\"Total_Volume\"] / session_efficiency[\"Set_Count\"]\n",
    "\n",
    "ax2.bar(range(len(session_efficiency)), session_efficiency[\"Vol_Per_Set\"], \n",
    "        color=\"#8a2be2\", edgecolor=\"black\", linewidth=1.5, alpha=0.8)\n",
    "ax2.axhline(y=session_efficiency[\"Vol_Per_Set\"].mean(), color=\"red\", linestyle=\"--\", \n",
    "            linewidth=2, label=f\"Avg: {session_efficiency['Vol_Per_Set'].mean():.0f} kg/set\")\n",
    "ax2.set_xticks(range(len(session_efficiency)))\n",
    "ax2.set_xticklabels([str(d) for d in session_efficiency.index], rotation=45, ha=\"right\")\n",
    "ax2.set_ylabel(\"Volume per Set (kg)\")\n",
    "ax2.set_xlabel(\"Session Date\")\n",
    "ax2.set_title(\"Session Density: Average Volume per Set\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Training style summary\n",
    "dominant_zone = zone_counts.idxmax()\n",
    "print(f\"\\nDominant training style: {dominant_zone.replace(chr(10), ' ')} ({zone_counts.max()}/{total} sets, {zone_counts.max()/total*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_milestones",
   "metadata": {},
   "source": [
    "## 2026 Milestone Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_milestones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_milestone_progress(df):\n",
    "    \"\"\"Calculate progress toward each milestone goal.\"\"\"\n",
    "    today = pd.Timestamp(datetime.now())\n",
    "    plot_data = []\n",
    "    \n",
    "    for move, targets in MILESTONES.items():\n",
    "        # Find matching movements (case-insensitive partial match)\n",
    "        family_df = df[df[\"Movement\"].str.contains(move, case=False, na=False)]\n",
    "        \n",
    "        if not family_df.empty:\n",
    "            best_row = family_df.loc[family_df[\"e1RM\"].idxmax()]\n",
    "            current_e1rm = best_row[\"e1RM\"]\n",
    "            days_ago = (today - best_row[\"Timestamp\"]).days\n",
    "        else:\n",
    "            current_e1rm, days_ago = 0, 365\n",
    "        \n",
    "        for weight, reps in targets:\n",
    "            target_e1rm = weight * (1 + reps / 30)\n",
    "            plot_data.append({\n",
    "                \"Goal\": f\"{move} ({weight}kg x {reps})\",\n",
    "                \"Current\": current_e1rm,\n",
    "                \"Target\": target_e1rm,\n",
    "                \"Days Ago\": days_ago,\n",
    "                \"Pct\": (current_e1rm / target_e1rm * 100) if target_e1rm > 0 else 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(plot_data)\n",
    "\n",
    "m_df = calculate_milestone_progress(df)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Background: target bars\n",
    "ax.barh(m_df[\"Goal\"], m_df[\"Target\"], color=\"grey\", alpha=0.15, label=\"Target\")\n",
    "\n",
    "# Foreground: current progress with color gradient\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(m_df)))\n",
    "ax.barh(m_df[\"Goal\"], m_df[\"Current\"], color=colors)\n",
    "\n",
    "# Annotations\n",
    "for i, row in m_df.iterrows():\n",
    "    color = \"green\" if row[\"Pct\"] >= 100 else \"black\"\n",
    "    ax.text(row[\"Current\"] + 2, i, f\"{row['Pct']:.0f}%\", va=\"center\", fontweight=\"bold\", color=color, fontsize=11)\n",
    "\n",
    "ax.axvline(x=120, color=\"red\", linestyle=\"--\", alpha=0.4, linewidth=2, label=\"120kg Reference\")\n",
    "ax.set_xlabel(\"Estimated 1RM (kg)\")\n",
    "ax.set_title(\"2026 Strength Milestone Progress\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.invert_yaxis()  # Top-to-bottom order\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n=== Milestone Summary ===\")\n",
    "for _, row in m_df.iterrows():\n",
    "    status = \"ACHIEVED\" if row[\"Pct\"] >= 100 else f\"{row['Pct']:.0f}%\"\n",
    "    print(f\"{row['Goal']:40} {status:>10} (PR {row['Days Ago']}d ago)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ackldgiq78o",
   "metadata": {},
   "source": [
    "## Relative Strength & Lift Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nxw93q3b3l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biomechanical strength ratio benchmarks (relative to Deadlift = 1.0)\n",
    "# These are approximate ratios for balanced strength\n",
    "RATIO_BENCHMARKS = {\n",
    "    \"Deadlift\": 1.0,\n",
    "    \"Squat\": 0.85,        # Squat ~85% of deadlift\n",
    "    \"Bench Press\": 0.65,  # Bench ~65% of deadlift  \n",
    "    \"Row\": 0.65,          # Row should roughly match bench\n",
    "    \"Overhead Press\": 0.42  # OHP ~65% of bench, ~42% of deadlift\n",
    "}\n",
    "\n",
    "def get_best_e1rm(df, search_term):\n",
    "    \"\"\"Get best e1RM for a movement pattern.\"\"\"\n",
    "    matches = df[df[\"Movement\"].str.contains(search_term, case=False, na=False)]\n",
    "    return matches[\"e1RM\"].max() if not matches.empty else 0\n",
    "\n",
    "# Calculate current maxes\n",
    "current_maxes = {\n",
    "    \"Deadlift\": get_best_e1rm(df, \"Deadlift\"),\n",
    "    \"Squat\": get_best_e1rm(df, \"Squat\"),\n",
    "    \"Bench Press\": get_best_e1rm(df, \"Bench|DB Press\"),\n",
    "    \"Row\": get_best_e1rm(df, \"Row\"),\n",
    "    \"Overhead Press\": get_best_e1rm(df, \"Overhead Press|OHP\")\n",
    "}\n",
    "\n",
    "# Use deadlift as reference (or strongest lift if no deadlift)\n",
    "reference_lift = current_maxes[\"Deadlift\"] if current_maxes[\"Deadlift\"] > 0 else max(current_maxes.values())\n",
    "\n",
    "if reference_lift > 0:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    # 1. Actual vs Expected Ratios (radar-style bar comparison)\n",
    "    lifts = list(RATIO_BENCHMARKS.keys())\n",
    "    expected = [RATIO_BENCHMARKS[l] * reference_lift for l in lifts]\n",
    "    actual = [current_maxes[l] for l in lifts]\n",
    "    \n",
    "    x = np.arange(len(lifts))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, expected, width, label=\"Expected (Balanced)\", color=\"grey\", alpha=0.5, edgecolor=\"black\")\n",
    "    bars2 = ax1.bar(x + width/2, actual, width, label=\"Your Current\", color=\"#2ca02c\", edgecolor=\"black\")\n",
    "    \n",
    "    ax1.set_ylabel(\"Estimated 1RM (kg)\")\n",
    "    ax1.set_title(\"Lift Balance: Expected vs Actual\")\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(lifts, rotation=15, ha=\"right\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add ratio annotations\n",
    "    for i, (exp, act) in enumerate(zip(expected, actual)):\n",
    "        if exp > 0:\n",
    "            ratio = act / exp * 100\n",
    "            color = \"green\" if 85 <= ratio <= 115 else (\"orange\" if 70 <= ratio <= 130 else \"red\")\n",
    "            ax1.text(i + width/2, act + 2, f\"{ratio:.0f}%\", ha=\"center\", fontweight=\"bold\", color=color, fontsize=10)\n",
    "    \n",
    "    # 2. Strength Ratio Spider/Polar Chart\n",
    "    ax2 = plt.subplot(122, projection=\"polar\")\n",
    "    \n",
    "    # Normalize to percentage of expected\n",
    "    ratios = [current_maxes[l] / (RATIO_BENCHMARKS[l] * reference_lift) * 100 \n",
    "              if RATIO_BENCHMARKS[l] * reference_lift > 0 else 0 for l in lifts]\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(lifts), endpoint=False).tolist()\n",
    "    ratios_closed = ratios + ratios[:1]\n",
    "    angles_closed = angles + angles[:1]\n",
    "    \n",
    "    # 100% reference circle\n",
    "    ax2.plot(angles_closed, [100] * len(angles_closed), color=\"grey\", linestyle=\"--\", linewidth=2, alpha=0.5, label=\"Balanced (100%)\")\n",
    "    ax2.fill(angles_closed, [100] * len(angles_closed), color=\"grey\", alpha=0.1)\n",
    "    \n",
    "    # Actual ratios\n",
    "    ax2.plot(angles_closed, ratios_closed, color=\"#8a2be2\", linewidth=2.5, marker=\"o\", markersize=8)\n",
    "    ax2.fill(angles_closed, ratios_closed, color=\"#da70d6\", alpha=0.3)\n",
    "    \n",
    "    ax2.set_xticks(angles)\n",
    "    ax2.set_xticklabels(lifts, fontsize=11, fontweight=\"bold\")\n",
    "    ax2.set_ylim(0, max(150, max(ratios) + 20))\n",
    "    ax2.set_title(\"Strength Balance Radar\\n(100% = Biomechanically Balanced)\", pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Imbalance analysis\n",
    "    print(\"\\n=== Strength Balance Analysis ===\")\n",
    "    for lift in lifts:\n",
    "        expected_val = RATIO_BENCHMARKS[lift] * reference_lift\n",
    "        actual_val = current_maxes[lift]\n",
    "        if expected_val > 0:\n",
    "            ratio = actual_val / expected_val * 100\n",
    "            status = \"BALANCED\" if 85 <= ratio <= 115 else (\"WEAK\" if ratio < 85 else \"STRONG\")\n",
    "            print(f\"{lift:20} {actual_val:6.1f}kg / {expected_val:6.1f}kg expected = {ratio:5.0f}% [{status}]\")\n",
    "else:\n",
    "    print(\"Need deadlift or other compound lift data for ratio analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v1mxgx53m9c",
   "metadata": {},
   "source": [
    "## PR Timeline & Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5z3f5zofvd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find PR (personal record) for each movement over time\n",
    "def calculate_prs(df):\n",
    "    \"\"\"Track cumulative PRs for each movement.\"\"\"\n",
    "    pr_records = []\n",
    "    movement_prs = {}  # Track current PR for each movement\n",
    "    \n",
    "    for _, row in df.sort_values(\"Timestamp\").iterrows():\n",
    "        move = row[\"Movement\"]\n",
    "        e1rm = row[\"e1RM\"]\n",
    "        date = row[\"Date\"]\n",
    "        \n",
    "        if move not in movement_prs or e1rm > movement_prs[move]:\n",
    "            movement_prs[move] = e1rm\n",
    "            pr_records.append({\n",
    "                \"Date\": date,\n",
    "                \"Movement\": move,\n",
    "                \"e1RM\": e1rm,\n",
    "                \"Load_kg\": row[\"Load_kg\"],\n",
    "                \"Reps\": row[\"Reps\"]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(pr_records)\n",
    "\n",
    "pr_df = calculate_prs(df)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# 1. PR Timeline - scatter plot of all PRs\n",
    "movements = pr_df[\"Movement\"].unique()\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(movements)))\n",
    "move_colors = dict(zip(movements, colors))\n",
    "\n",
    "for move in movements:\n",
    "    move_prs = pr_df[pr_df[\"Movement\"] == move]\n",
    "    ax1.scatter(move_prs[\"Date\"], move_prs[\"e1RM\"], \n",
    "                label=move, s=150, alpha=0.8, edgecolor=\"black\", linewidth=1.5,\n",
    "                c=[move_colors[move]])\n",
    "    # Connect PRs with lines\n",
    "    if len(move_prs) > 1:\n",
    "        ax1.plot(move_prs[\"Date\"], move_prs[\"e1RM\"], \n",
    "                 alpha=0.3, linewidth=1.5, c=move_colors[move])\n",
    "\n",
    "ax1.set_ylabel(\"Estimated 1RM (kg)\")\n",
    "ax1.set_title(\"PR Timeline: Personal Records Over Time\")\n",
    "ax1.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", fontsize=9)\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 2. PR Count by Date - cumulative PRs\n",
    "pr_counts = pr_df.groupby(\"Date\").size().cumsum()\n",
    "ax2.fill_between(pr_counts.index, pr_counts.values, alpha=0.3, color=\"#8a2be2\")\n",
    "ax2.plot(pr_counts.index, pr_counts.values, color=\"#8a2be2\", linewidth=2.5, marker=\"o\", markersize=8)\n",
    "ax2.set_ylabel(\"Cumulative PR Count\")\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.set_title(\"PR Accumulation: Total Records Set\")\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PR Table\n",
    "print(\"\\n=== Current Personal Records ===\")\n",
    "current_prs = pr_df.sort_values(\"Date\").drop_duplicates(\"Movement\", keep=\"last\").sort_values(\"e1RM\", ascending=False)\n",
    "for _, row in current_prs.iterrows():\n",
    "    print(f\"{row['Movement']:30} {row['e1RM']:6.1f}kg  ({row['Load_kg']}kg x {row['Reps']})  [{row['Date']}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
